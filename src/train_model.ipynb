{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c11d6883-07d1-4057-98f5-ab7e67716a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete for dt.\n",
      "AUC for dt: 0.8326502732240437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/21 22:24:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'TitanicClassifier' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'TitanicClassifier'.\n"
     ]
    }
   ],
   "source": [
    "# All necessary imports are included here\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "def train_model(model_name: str):\n",
    "    \"\"\"\n",
    "    Loads ML-ready data, trains a selected model, and logs with MLflow.\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_run\") as run:\n",
    "        spark = SparkSession.builder.appName(\"TitanicModelTraining\").getOrCreate()\n",
    "        \n",
    "        # Use the absolute path to avoid issues\n",
    "        ml_ready_df = spark.read.parquet('C:/Users/user/AI_LAB_PROJECT/data/processed/titanic_ml_ready')\n",
    "        train_data, test_data = ml_ready_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "        # --- Model Selection and Training ---\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "\n",
    "        if model_name == \"lr\":\n",
    "            model_instance = LogisticRegression(featuresCol=\"features\", labelCol=\"Survived\")\n",
    "            model = model_instance.fit(train_data)\n",
    "        \n",
    "        elif model_name == \"rf\":\n",
    "            num_trees = 100\n",
    "            mlflow.log_param(\"num_trees\", num_trees)\n",
    "            model_instance = RandomForestClassifier(featuresCol=\"features\", labelCol=\"Survived\", numTrees=num_trees)\n",
    "            model = model_instance.fit(train_data)\n",
    "            \n",
    "        elif model_name == \"dt\":\n",
    "            max_depth = 5\n",
    "            mlflow.log_param(\"max_depth\", max_depth)\n",
    "            model_instance = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"Survived\", maxDepth=max_depth)\n",
    "            model = model_instance.fit(train_data)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type specified.\")\n",
    "\n",
    "        print(f\"Model training complete for {model_name}.\")\n",
    "\n",
    "        # --- Evaluation and Logging ---\n",
    "        predictions = model.transform(test_data)\n",
    "        evaluator_auc = BinaryClassificationEvaluator(labelCol=\"Survived\")\n",
    "        auc = evaluator_auc.evaluate(predictions)\n",
    "        mlflow.log_metric(\"test_auc\", auc)\n",
    "        print(f\"AUC for {model_name}: {auc}\")\n",
    "\n",
    "        # input_example = train_data.limit(1)\n",
    "\n",
    "        mlflow.spark.log_model(\n",
    "        model,\n",
    "        \"spark-model\",\n",
    "        registered_model_name=\"TitanicClassifier\"\n",
    "        )\n",
    "        \n",
    "        # Note: The promote_best_model function is not included here for simplicity,\n",
    "        # but you can add it back if you want to test that logic as well.\n",
    "        \n",
    "        spark.stop()\n",
    "\n",
    "# --- Main execution block for Jupyter Notebook ---\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model_name\",\n",
    "        type=str,\n",
    "        default=\"lr\",\n",
    "        choices=[\"lr\", \"rf\", \"dt\"],\n",
    "        help=\"Specify the model to train: lr, rf, or dt.\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    train_model(model_name=args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e40d0-bd97-4e32-9cfa-70baf536f8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
